{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Joe Biden's and Donald Trump's tweets during the coronavirus pandemic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "* [1. Importing Packages](#importing_packages)\n",
    "* [2. Loading the Data](#load_data)\n",
    "* [3. Data Cleaning and Preparation](#data_clean)\n",
    "* [4. Exploring the Data: Aggregate and Frequency statistics](#explore_data)\n",
    "* [5. Sentiment Analysis](#sentiment_analysis)\n",
    "* [6. Topic Modeling](#topic_modeling)\n",
    "* [7. Classification](#classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing packages <a class=\"anchor\" id=\"importing_packages\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "from nltk import everygrams\n",
    "from nltk import ngrams\n",
    "from nltk import FreqDist\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora, models\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm, metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "pd.options.mode.chained_assignment = None\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Data<a class=\"anchor\" id=\"load_data\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df = pd.read_csv(\"trump.csv\")\n",
    "biden_df = pd.read_csv(\"biden.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>id_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @USNoodlesA: ðŸ”¥This amazing American @TheLeo...</td>\n",
       "      <td>08-09-2020 02:30:54</td>\n",
       "      <td>12113</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1292287207533936645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @drawandstrike: ADDENDUM:This is 100% corre...</td>\n",
       "      <td>08-09-2020 02:26:15</td>\n",
       "      <td>8666</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1292286038518280192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @hale_razor: Just think of it as DACA for A...</td>\n",
       "      <td>08-09-2020 02:24:25</td>\n",
       "      <td>9198</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1292285575454691330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @KurtSchlichter: Why is the DACA executive ...</td>\n",
       "      <td>08-09-2020 02:21:58</td>\n",
       "      <td>6692</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1292284959533793282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @marklevinshow: 1. President Trump had no c...</td>\n",
       "      <td>08-09-2020 02:21:32</td>\n",
       "      <td>19090</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1292284850125316096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>I will be signing our very large and comprehen...</td>\n",
       "      <td>12-31-2019 14:16:40</td>\n",
       "      <td>22730</td>\n",
       "      <td>95208</td>\n",
       "      <td>False</td>\n",
       "      <td>1212014713808273410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>President Putin of Russia called to thank me a...</td>\n",
       "      <td>12-31-2019 14:06:09</td>\n",
       "      <td>29025</td>\n",
       "      <td>141918</td>\n",
       "      <td>False</td>\n",
       "      <td>1212012065440894976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>Armed congregants quickly stopped a crazed chu...</td>\n",
       "      <td>12-31-2019 13:53:10</td>\n",
       "      <td>25719</td>\n",
       "      <td>114701</td>\n",
       "      <td>False</td>\n",
       "      <td>1212008798849814528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>Iran killed an American contractor wounding ma...</td>\n",
       "      <td>12-31-2019 12:02:47</td>\n",
       "      <td>37287</td>\n",
       "      <td>150318</td>\n",
       "      <td>False</td>\n",
       "      <td>1211981022084128768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>The Democrats will do anything to avoid a tria...</td>\n",
       "      <td>12-31-2019 11:16:26</td>\n",
       "      <td>25707</td>\n",
       "      <td>101260</td>\n",
       "      <td>False</td>\n",
       "      <td>1211969354499284992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7033 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text           created_at  \\\n",
       "0     RT @USNoodlesA: ðŸ”¥This amazing American @TheLeo...  08-09-2020 02:30:54   \n",
       "1     RT @drawandstrike: ADDENDUM:This is 100% corre...  08-09-2020 02:26:15   \n",
       "2     RT @hale_razor: Just think of it as DACA for A...  08-09-2020 02:24:25   \n",
       "3     RT @KurtSchlichter: Why is the DACA executive ...  08-09-2020 02:21:58   \n",
       "4     RT @marklevinshow: 1. President Trump had no c...  08-09-2020 02:21:32   \n",
       "...                                                 ...                  ...   \n",
       "7028  I will be signing our very large and comprehen...  12-31-2019 14:16:40   \n",
       "7029  President Putin of Russia called to thank me a...  12-31-2019 14:06:09   \n",
       "7030  Armed congregants quickly stopped a crazed chu...  12-31-2019 13:53:10   \n",
       "7031  Iran killed an American contractor wounding ma...  12-31-2019 12:02:47   \n",
       "7032  The Democrats will do anything to avoid a tria...  12-31-2019 11:16:26   \n",
       "\n",
       "      retweet_count  favorite_count  is_retweet               id_str  \n",
       "0             12113               0        True  1292287207533936645  \n",
       "1              8666               0        True  1292286038518280192  \n",
       "2              9198               0        True  1292285575454691330  \n",
       "3              6692               0        True  1292284959533793282  \n",
       "4             19090               0        True  1292284850125316096  \n",
       "...             ...             ...         ...                  ...  \n",
       "7028          22730           95208       False  1212014713808273410  \n",
       "7029          29025          141918       False  1212012065440894976  \n",
       "7030          25719          114701       False  1212008798849814528  \n",
       "7031          37287          150318       False  1211981022084128768  \n",
       "7032          25707          101260       False  1211969354499284992  \n",
       "\n",
       "[7033 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>id_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We canâ€™t let Donald Trump destroy the U.S. Pos...</td>\n",
       "      <td>2020-08-09 19:15:00</td>\n",
       "      <td>10158</td>\n",
       "      <td>54082</td>\n",
       "      <td>False</td>\n",
       "      <td>1292539896465416192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's been six years since Michael Brown's life...</td>\n",
       "      <td>2020-08-09 17:00:00</td>\n",
       "      <td>6281</td>\n",
       "      <td>34913</td>\n",
       "      <td>False</td>\n",
       "      <td>1292505925685633025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Our planet canâ€™t take four more years of Donal...</td>\n",
       "      <td>2020-08-09 15:00:02</td>\n",
       "      <td>17283</td>\n",
       "      <td>102639</td>\n",
       "      <td>False</td>\n",
       "      <td>1292475731172261894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @TeamJoe: We seriously canâ€™t wait to see wh...</td>\n",
       "      <td>2020-08-09 14:24:10</td>\n",
       "      <td>797</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1292466709006344193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Giving the Trump administration another four y...</td>\n",
       "      <td>2020-08-09 13:00:00</td>\n",
       "      <td>10095</td>\n",
       "      <td>40664</td>\n",
       "      <td>False</td>\n",
       "      <td>1292445526005252096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>RT @TeamJoe: Let's clear up the confusion abou...</td>\n",
       "      <td>2019-07-31 13:22:52</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1156555830222831617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>RT @TeamJoe: A medida que los ricos se hacen m...</td>\n",
       "      <td>2019-07-31 02:13:18</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1156387329663258624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>RT @TeamJoe: As the rich get richer, middle-cl...</td>\n",
       "      <td>2019-07-31 02:13:16</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1156387322587488257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>RT @TeamJoe: President Trump doesnâ€™t get the b...</td>\n",
       "      <td>2019-07-31 01:57:35</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1156383375030214657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>RT @TeamJoe: We must recognize that the impact...</td>\n",
       "      <td>2019-07-31 01:42:57</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1156379690904559622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text           created_at  \\\n",
       "0     We canâ€™t let Donald Trump destroy the U.S. Pos...  2020-08-09 19:15:00   \n",
       "1     It's been six years since Michael Brown's life...  2020-08-09 17:00:00   \n",
       "2     Our planet canâ€™t take four more years of Donal...  2020-08-09 15:00:02   \n",
       "3     RT @TeamJoe: We seriously canâ€™t wait to see wh...  2020-08-09 14:24:10   \n",
       "4     Giving the Trump administration another four y...  2020-08-09 13:00:00   \n",
       "...                                                 ...                  ...   \n",
       "3195  RT @TeamJoe: Let's clear up the confusion abou...  2019-07-31 13:22:52   \n",
       "3196  RT @TeamJoe: A medida que los ricos se hacen m...  2019-07-31 02:13:18   \n",
       "3197  RT @TeamJoe: As the rich get richer, middle-cl...  2019-07-31 02:13:16   \n",
       "3198  RT @TeamJoe: President Trump doesnâ€™t get the b...  2019-07-31 01:57:35   \n",
       "3199  RT @TeamJoe: We must recognize that the impact...  2019-07-31 01:42:57   \n",
       "\n",
       "      retweet_count  favorite_count  is_retweet               id_str  \n",
       "0             10158           54082       False  1292539896465416192  \n",
       "1              6281           34913       False  1292505925685633025  \n",
       "2             17283          102639       False  1292475731172261894  \n",
       "3               797               0        True  1292466709006344193  \n",
       "4             10095           40664       False  1292445526005252096  \n",
       "...             ...             ...         ...                  ...  \n",
       "3195            248               0        True  1156555830222831617  \n",
       "3196             54               0        True  1156387329663258624  \n",
       "3197            165               0        True  1156387322587488257  \n",
       "3198            215               0        True  1156383375030214657  \n",
       "3199             86               0        True  1156379690904559622  \n",
       "\n",
       "[3200 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Cleaning and Preparation<a class=\"anchor\" id=\"data_clean\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "global stop_words\n",
    "stop_words = stopwords.words('english')\n",
    "custom_stopwords = ['amp', 'youre', 'dont','wont', 'got']\n",
    "stop_words.extend(custom_stopwords)\n",
    "\n",
    "def detect_language(X):\n",
    "    from langdetect import detect\n",
    "    try:\n",
    "        lang = detect(X)\n",
    "        return(lang)\n",
    "    except:\n",
    "        return(\"other\")\n",
    "    \n",
    "def remove_url_punctuation(X):\n",
    "    \"\"\" Replace URLS, punctuations, hashtags found in a text string with nothing.\n",
    "    Change to lowercase\"\"\"\n",
    "    # Try with just simple /w+ regex.       \n",
    "    url_pattern = re.compile(r'https:?://\\S+|www\\.\\S+')\n",
    "    replace_url = url_pattern.sub(r'', str(X))\n",
    "    punct_pattern = re.compile(r'[^\\w\\s]')\n",
    "    no_punct = punct_pattern.sub(r'', replace_url).lower()\n",
    "    no_punct = no_punct.replace('\\n', ' ')\n",
    "    no_punct = no_punct.replace('\\t', ' ')\n",
    "    return no_punct\n",
    "\n",
    "def split_words(X):\n",
    "    \"\"\"\"\" Split tweets into words for NLP\"\"\"\n",
    "    split_word_list = X.split(\" \")\n",
    "    return split_word_list\n",
    "\n",
    "def remove_stopwords(X):\n",
    "    filtered_words = []\n",
    "    global stop_words\n",
    "    for word in X:\n",
    "        if word not in stop_words and len(word) > 2 and word != 'nan':\n",
    "            filtered_words.append(word)\n",
    "    return filtered_words\n",
    "\n",
    "# All the above in one function\n",
    "def basic_processing(text):\n",
    "    clean_text = remove_url_punctuation(text)\n",
    "    tokens = split_words(clean_text)\n",
    "    tokens = remove_stopwords(tokens) \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Biden tweets since the emergence of [COVID19](https://www.who.int/docs/default-source/coronaviruse/situation-reports/20200121-sitrep-1-2019-ncov.pdf). Trump dataset already filtered by start date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = pd.to_datetime('31-12-2019')\n",
    "biden_df['created_at'] = pd.to_datetime(biden_df['created_at'])\n",
    "trump_df['created_at'] = pd.to_datetime(trump_df['created_at'])\n",
    "biden_df = biden_df.loc[biden_df['created_at'] >= START_DATE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump has 3843 retweets. 54.64 % of his tweets are retweets.\n",
      "Biden has 73 retweets. 3.79 % of his tweets are retweets.\n"
     ]
    }
   ],
   "source": [
    "# Note: Not using is_retweet column since data incorrectly labelled from trumptwitterarchive. \n",
    "# Using starts with 'RT' is more reliable.\n",
    "trump_retweets = trump_df[trump_df.text.str.startswith('RT ') == True]\n",
    "biden_retweets = biden_df[biden_df.text.str.startswith('RT ') == True]\n",
    "print('Trump has', len(trump_retweets), 'retweets.', round(len(trump_retweets)/len(trump_df) * 100, 2), '% of his tweets are retweets.')\n",
    "print('Biden has', len(biden_retweets), 'retweets.', round(len(biden_retweets)/len(biden_df) * 100,2), '% of his tweets are retweets.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df = trump_df[trump_df.text.str.startswith('RT ') == False]\n",
    "biden_df = biden_df[biden_df.text.str.startswith('RT ') == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove non-English tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df['en'] = trump_df['text'].apply(detect_language)\n",
    "biden_df['en'] = biden_df['text'].apply(detect_language)\n",
    "\n",
    "trump_df = trump_df[trump_df['en'] == 'en']\n",
    "biden_df = biden_df[biden_df['en'] == 'en']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuation, special characters, and hashtags in tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df['clean_text'] = trump_df['text'].apply(remove_url_punctuation)\n",
    "biden_df['clean_text'] = biden_df['text'].apply(remove_url_punctuation)\n",
    "print(trump_df['text'].head())\n",
    "print('-------------------------------------')\n",
    "print(trump_df['clean_text'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df['tokens'] = trump_df['clean_text'].apply(split_words)\n",
    "biden_df['tokens'] = biden_df['clean_text'].apply(split_words)\n",
    "print(trump_df['clean_text'].head())\n",
    "print('-------------------------------------')\n",
    "print(trump_df['tokens'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stop Words with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df['tokens'] = trump_df['tokens'].apply(remove_stopwords)\n",
    "biden_df['tokens'] = biden_df['tokens'].apply(remove_stopwords)\n",
    "print(trump_df['tokens'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Exploring the Data: Aggregate and Frequency Statistics<a class=\"anchor\" id=\"explore_data\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How engaging are their tweets?: Viewing the average number of retweets and favorites. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_rt_avg = trump_df.mean()['retweet_count']\n",
    "print(\"Trump retweet average:\", trump_rt_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_favorite_avg = trump_df.mean()['favorite_count']\n",
    "print(\"Trump favorite average:\", trump_favorite_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_most_rts = trump_df.loc[trump_df['retweet_count'].idxmax()].text\n",
    "print(\"Trump's most retweeted and favorited tweet:\", trump_most_rts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_rt_avg = biden_df.mean()['retweet_count']\n",
    "print(\"Biden retweet average:\", biden_rt_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_favorite_avg = biden_df.mean()['favorite_count']\n",
    "print(\"Biden favorite average:\", biden_favorite_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_most_rts = biden_df.loc[biden_df['retweet_count'].idxmax()].text\n",
    "print(\"Biden's most retweeted and favorited tweet:\", biden_most_rts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how much more retweets and favorites trump gets on average than Biden\n",
    "print(\"Trump gets\", round(trump_rt_avg / biden_rt_avg, 2), \"times more retweets than Biden.\" )\n",
    "print(\"That's an increase of\", round(100 * (trump_rt_avg - biden_rt_avg) / biden_rt_avg, 2) ,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trump gets\", round(trump_favorite_avg / biden_favorite_avg, 2), \"times more favorites than Biden.\" )\n",
    "print(\"That's an increase of\", round(100 * (trump_favorite_avg - biden_favorite_avg) / biden_favorite_avg, 2) ,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looks like Trump gets much more retweets and favorites than Biden. Let's use boxplots to visualize the differences more clearly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-notebook')\n",
    "plt.figure(figsize=(6, 10))\n",
    "plt.boxplot([trump_df['retweet_count'], biden_df['retweet_count']], labels=['Trump', 'Biden'], autorange=False)\n",
    "\n",
    "plt.ylabel('Retweets')\n",
    "plt.title('Trump vs Biden Retweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 10))\n",
    "plt.boxplot([trump_df['favorite_count'], biden_df['favorite_count']], labels=['Trump', 'Biden'], autorange=False)\n",
    "plt.ylabel('Favorites')\n",
    "plt.title('Trump vs Biden Favorites')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The box plots clearly show that on average Biden has less engagement than Trump on Twitter, except for his one outlier tweet that went viral. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which words and n-grams do they use the most?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_tokens = trump_df['tokens'].explode()\n",
    "biden_tokens = biden_df['tokens'].explode()\n",
    "\n",
    "trump_unigrams = FreqDist(ngrams(trump_tokens, 1))\n",
    "biden_unigrams = FreqDist(ngrams(biden_tokens, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "NUM_NGRAMS = 20\n",
    "\n",
    "pd.Series(ngrams(trump_tokens, 1)).value_counts()[:NUM_NGRAMS].sort_values().plot.barh(color='orangered', width=.7, figsize=(12,8))\n",
    "plt.title(\"Trump's Top 20 Unigrams\")\n",
    "plt.ylabel('Unigram')\n",
    "plt.xlabel('# of occurrences')\n",
    "trump_unigrams.most_common(NUM_NGRAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(ngrams(biden_tokens, 1)).value_counts()[:NUM_NGRAMS].sort_values().plot.barh(color='dodgerblue', width=.7, figsize=(12,8))\n",
    "plt.title(\"Biden's Top 20 Unigrams\")\n",
    "plt.ylabel('Unigram')\n",
    "plt.xlabel('# of occurrences')\n",
    "biden_unigrams.most_common(NUM_NGRAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_bigrams = FreqDist(ngrams(trump_tokens, 2))\n",
    "biden_bigrams = FreqDist(ngrams(biden_tokens, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(ngrams(trump_tokens, 2)).value_counts()[:NUM_NGRAMS].sort_values().plot.barh(color='orangered', width=.7, figsize=(12,8))\n",
    "plt.title(\"Trump's Top 20 Bigrams\")\n",
    "plt.ylabel('Bigram')\n",
    "plt.xlabel('# of occurrences')\n",
    "trump_bigrams.most_common(NUM_NGRAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(ngrams(biden_tokens, 2)).value_counts()[:NUM_NGRAMS].sort_values().plot.barh(color='dodgerblue', width=.7, figsize=(12,8))\n",
    "plt.title(\"Bidens's Top 20 Bigrams\")\n",
    "plt.ylabel('Bigram')\n",
    "plt.xlabel('# of occurrences')\n",
    "biden_bigrams.most_common(NUM_NGRAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_trigrams = FreqDist(ngrams(trump_tokens, 3))\n",
    "biden_trigrams = FreqDist(ngrams(biden_tokens, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(ngrams(trump_tokens, 3)).value_counts()[:NUM_NGRAMS].sort_values().plot.barh(color='orangered', width=.7, figsize=(12,8))\n",
    "plt.title(\"Trump's Top 20 Trigrams\")\n",
    "plt.ylabel('Trigram')\n",
    "plt.xlabel('# of occurrences')\n",
    "trump_trigrams.most_common(NUM_NGRAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(ngrams(biden_tokens, 3)).value_counts()[:NUM_NGRAMS].sort_values().plot.barh(color='dodgerblue', width=.7, figsize=(12,8))\n",
    "plt.title(\"Biden's Top 20 Trigrams\")\n",
    "plt.ylabel('Trigram')\n",
    "plt.xlabel('# of occurrences')\n",
    "biden_trigrams.most_common(NUM_NGRAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-5 grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(everygrams(trump_tokens, min_len= 4, max_len=5)).value_counts()[:NUM_NGRAMS].sort_values().plot.barh(color='orangered', width=.7, figsize=(12,8))\n",
    "plt.title(\"Trump's Top 20 4-5grams\")\n",
    "plt.ylabel('4-5grams')\n",
    "plt.xlabel('# of occurrences')\n",
    "\n",
    "trump_4_5_grams = FreqDist(everygrams(trump_tokens, min_len= 4, max_len=5))\n",
    "trump_4_5_grams.most_common(NUM_NGRAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(everygrams(biden_tokens, min_len= 4, max_len=5)).value_counts()[:NUM_NGRAMS].sort_values().plot.barh(color='dodgerblue', width=.7, figsize=(12,8))\n",
    "plt.title(\"Biden's Top 20 4-5grams\")\n",
    "plt.ylabel('4-5gram')\n",
    "plt.xlabel('# of occurrences')\n",
    "\n",
    "biden_4_5_grams = FreqDist(everygrams(biden_tokens, min_len= 4, max_len=5)).most_common(NUM_NGRAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above n-grams, it seems that Biden talks a lot about gun violence, healthcare, and climate change, while Trump talks a lot about fake news, whitehouse conferences, endorsements and republican party ratings. They also both mention each other a lot. Question is, how much? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many times do they mention each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_tweets_contain_biden = trump_df[trump_df['text'].str.lower().str.contains(\"joe|biden\")]\n",
    "print(len(trump_tweets_contain_biden), \"Trump tweets mention Joe Biden.\")\n",
    "trump_mention_biden_percent = round(100 * len(trump_tweets_contain_biden)/ len(trump_df), 2)\n",
    "print(\"That means\", trump_mention_biden_percent,  \"% of Trump tweets mention Joe Biden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_tweets_contain_trump = biden_df[biden_df['text'].str.lower().str.contains(\"trump|donald\")]\n",
    "print(len(biden_tweets_contain_trump), \"Biden tweets mention Donald Trump.\")\n",
    "biden_mention_trump_percent = round(100 * len(biden_tweets_contain_trump)/ len(biden_df), 2)\n",
    "print(\"That means\", biden_mention_trump_percent,  \"% of Biden tweets mention Donald Trump\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many times do they mention the coronavirus? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corona_regex = \"covid|corona|virus|pandemic\"\n",
    "biden_tweets_relate_corona = biden_df[biden_df['text'].str.lower().str.contains(corona_regex)]\n",
    "print(len(biden_tweets_relate_corona))\n",
    "biden_tweets_relate_corona_percent = round(100 * len(biden_tweets_relate_corona)/ len(biden_df), 2)\n",
    "print(\"That means\", biden_tweets_relate_corona_percent,  \"% of Biden tweets mention coronavirus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_tweets_relate_corona = trump_df[trump_df['text'].str.lower().str.contains(corona_regex)]\n",
    "print(len(trump_tweets_relate_corona))\n",
    "trump_tweets_relate_corona_percent = round(100 * len(trump_tweets_relate_corona)/ len(trump_df), 2)\n",
    "print(\"That means\", trump_tweets_relate_corona_percent,  \"% of Trump tweets mention coronavirus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biden tweets about the coronavirus nearly twice as much as Trump. Also while only ~7% of Trump tweets mention Joe Biden, nearly 31% of Biden tweets mention Trump."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How frequently do they tweet? Has the frequency of tweets changed as the pandemic evolved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_tweet_by_date = trump_df.groupby(by=trump_df['created_at'].dt.date).count()['text']\n",
    "plt.plot(trump_tweet_by_date.index.values, trump_tweet_by_date, color='orangered')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Tweets')\n",
    "plt.title('Number of Trump Tweets since December 31 2019')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_tweet_by_date = biden_df.groupby(by=biden_df['created_at'].dt.date).count()['text']\n",
    "plt.plot(biden_tweet_by_date.index.values, biden_tweet_by_date, color='dodgerblue')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Tweets')\n",
    "plt.title('Number of Biden Tweets since December 31 2019')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both candidates on the same figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trump_tweet_by_date.index.values, trump_tweet_by_date, 'orangered')\n",
    "plt.plot(biden_tweet_by_date.index.values, biden_tweet_by_date, 'dodgerblue')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Tweets')\n",
    "plt.title('Tweets since December 31 2019 ')\n",
    "plt.legend(['Trump', 'Biden'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graphs above, it seems that there are peaks and valleys. Future work would be to investigate the dates with more tweets than normal to see if those are linked with news events. Moreover, the variance in the number of tweets brings up the question if they tweet more on certain days over others?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do they prefer to tweet on certain days over others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekdays = [ 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "trump_tweets_by_weekday = trump_df.groupby(by=trump_df['created_at'].dt.day_name()).count().reindex(weekdays)['text']\n",
    "plt.bar(trump_tweets_by_weekday.index.values, trump_tweets_by_weekday, color='orangered')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Tweets')\n",
    "plt.title('Trump Tweets by Weekday')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_tweets_by_weekday = biden_df.groupby(by=biden_df['created_at'].dt.day_name()).count().reindex(weekdays)['text']\n",
    "plt.bar(biden_tweets_by_weekday.index.values, biden_tweets_by_weekday, color='dodgerblue')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Tweets')\n",
    "plt.title('Biden Tweets by Weekday')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that Biden tends to tweet most during the middle of the week and tapers off on the weekend. Whereas Trump tends to tweet consistently with a tendency to tweet more on Thursdays and Fridays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Sentiment Analysis<a class=\"anchor\" id=\"sentiment_analysis\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get polarity and subjectivity scores for candidate tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure subjectivity of a text. Subjectivity is in the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective\n",
    "def get_subjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "# Use polarity as a measure for sentiment. Polarity is in the range [-1.0, 1.0] where -1 is negative and +1 is positive sentiment\n",
    "def get_polarity(text):\n",
    "    return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df['Subjectivity'] = trump_df['clean_text'].apply(get_subjectivity)\n",
    "trump_df['Polarity'] = trump_df['clean_text'].apply(get_polarity)\n",
    "\n",
    "biden_df['Subjectivity'] = biden_df['clean_text'].apply(get_subjectivity)\n",
    "biden_df['Polarity'] = biden_df['clean_text'].apply(get_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trump_df['Polarity'])\n",
    "print(trump_df['Subjectivity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign positive, neutral, and negative labels to tweets based on polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(polarity):\n",
    "    if polarity > 0:\n",
    "        return 'Positive'\n",
    "    elif polarity == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df['Sentiment'] = trump_df['Polarity'].apply(get_sentiment)\n",
    "biden_df['Sentiment'] = biden_df['Polarity'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df['Sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Positive and Negative Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_most_positive = trump_df.nlargest(10, 'Polarity')\n",
    "print(\"Trump's top\", len(trump_most_negative), \"most positive tweets\" )\n",
    "\n",
    "for idx, tweet in enumerate(trump_most_positive['text']):\n",
    "    print(idx, tweet)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_most_negative = trump_df.nsmallest(10, 'Polarity')\n",
    "print(\"Trump's top\", len(trump_most_negative), \"most negative tweets\" )\n",
    "\n",
    "for idx, tweet in enumerate(trump_most_negative['text']):\n",
    "    print(idx, tweet)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_most_positive = biden_df.nlargest(10, 'Polarity')\n",
    "print(\"Biden's top\", len(biden_most_positive), \"most positive tweets\" )\n",
    "\n",
    "for idx, tweet in enumerate(biden_most_positive['text']):\n",
    "    print(idx, tweet)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_most_negative = biden_df.nsmallest(10, 'Polarity')\n",
    "print(\"Biden's top\", len(biden_most_negative), \"most negative tweets\" )\n",
    "\n",
    "for idx, tweet in enumerate(biden_most_negative['text']):\n",
    "    print(idx, tweet)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6)) \n",
    "plt.scatter(trump_df[\"Polarity\"], trump_df[\"Subjectivity\"], color='orangered')            \n",
    "plt.title('Trump Sentiment Analysis') \n",
    "plt.xlabel('Polarity') \n",
    "plt.ylabel('Subjectivity') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6)) \n",
    "plt.scatter(biden_df[\"Polarity\"], biden_df[\"Subjectivity\"], color='dodgerblue') \n",
    "\n",
    "plt.title('Biden Sentiment Analysis') \n",
    "plt.xlabel('Polarity') \n",
    "plt.ylabel('Subjectivity') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the counts of positive, netural, and negative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Trump Sentiments')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Counts')\n",
    "trump_df['Sentiment'].value_counts().plot(kind = 'bar', color='orangered')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Biden Sentiments')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Counts')\n",
    "biden_df['Sentiment'].value_counts().plot(kind = 'bar', color='dodgerblue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage of positive/negative tweets of each candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_trump_tweets = trump_df[trump_df.Sentiment == 'Positive']\n",
    "positive_trump_percent = round(len(positive_trump_tweets) / len(trump_df) * 100, 2)\n",
    "print(positive_trump_percent, '% of trump tweets are positive.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get % of trump tweets that are neutral\n",
    "neutral_trump_tweets = trump_df[trump_df.Sentiment == 'Neutral']\n",
    "neutral_trump_percent = round(len(neutral_trump_tweets) / len(trump_df) * 100, 2)\n",
    "print(neutral_trump_percent,'% of trump tweets are neutral.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_trump_tweets = trump_df[trump_df.Sentiment == 'Negative']\n",
    "negative_trump_percent = round(len(negative_trump_tweets) / len(trump_df) * 100, 2)\n",
    "print(negative_trump_percent, '% of trump tweets are negative.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "sentiments = ['positive', 'neutral', 'negative']\n",
    "percentages = [positive_trump_percent, neutral_trump_percent, negative_trump_percent]\n",
    "explode = [0.1, 0, 0]\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "pie_colors = ['mediumspringgreen', 'gainsboro', 'salmon']\n",
    "ax1.pie(percentages, explode=explode, labels=sentiments, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90, colors=pie_colors)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "ax1.set_title(\"Trump Sentiments\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_biden_tweets = biden_df[biden_df.Sentiment == 'Positive']\n",
    "positive_biden_percent = round(len(positive_biden_tweets) / len(biden_df) * 100, 2)\n",
    "print(positive_biden_percent, '% of biden tweets are positive.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_biden_tweets = biden_df[biden_df.Sentiment == 'Neutral']\n",
    "neutral_biden_percent = round(len(neutral_biden_tweets) / len(biden_df) * 100, 2)\n",
    "print(neutral_biden_percent, '% of biden tweets are neutral.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_biden_tweets = biden_df[biden_df.Sentiment == 'Negative']\n",
    "negative_biden_percent = round(len(negative_biden_tweets) / len(biden_df) * 100, 2)\n",
    "print(negative_biden_percent, '% of biden tweets are negative.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = [positive_biden_percent, neutral_biden_percent, negative_biden_percent]\n",
    "\n",
    "fig2, ax2 = plt.subplots()\n",
    "ax2.pie(percentages, explode=explode, labels=sentiments, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90, colors=pie_colors)\n",
    "ax2.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "ax2.set_title(\"Biden Sentiments\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, Trump has a larger proportion of tweets that are perceived as positive (~60% positive compared to Biden's 54% positive). I suspect this is due to Trump's tendency to exaggerate with frequent use of words such as 'great', 'wonderful', etc. Additionally, a slightly larger portion of tweets are negative in comparison to Biden's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Did their sentiments change as the pandemic evolved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_polarity_by_date = trump_df.groupby(by=trump_df['created_at'].dt.date).mean()['Polarity']\n",
    "plt.plot(trump_polarity_by_date.index.values, trump_polarity_by_date, color='orangered')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Polarity')\n",
    "plt.title('Trump Average Polarity since December 31 2019')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_polarity_by_date = biden_df.groupby(by=biden_df['created_at'].dt.date).mean()['Polarity']\n",
    "plt.plot(biden_polarity_by_date.index.values, biden_polarity_by_date, color='dodgerblue')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Polarity')\n",
    "plt.title('Biden Average Polarity since December 31 2019')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both on one plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trump_polarity_by_date.index.values, trump_polarity_by_date, color='orangered')\n",
    "plt.plot(biden_polarity_by_date.index.values, biden_polarity_by_date, color='dodgerblue')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Polarity')\n",
    "plt.title('Average Polarity since December 31 2019')\n",
    "plt.legend(['Trump', 'Biden'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There doesn't seem to be any clear trend from the data. Future work could include investigating the dates and tweets with the largest peaks/valleys to see if those correlate with any coronavirus news events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Topic Modeling with [LDA](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation)<a class=\"anchor\" id=\"topic_modeling\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peprocess data for topic modelling\n",
    "Remove words with fewer than three characters, perform lemmatization and stemming, include custom stopwords for each candidate to improve topic modelling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for topic model preprocessing\n",
    "custom_trump_stopwords = ['realdonaldtrump', 'great', 'pass']\n",
    "def stem_and_lemmatize(text):\n",
    "    return PorterStemmer().stem(WordNetLemmatizer().lemmatize(text))\n",
    "\n",
    "\n",
    "def lda_processing(tokens):\n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        if token not in custom_trump_stopwords:\n",
    "#         if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3 and token not in custom_trump_stopwords:\n",
    "            result.append(stem_and_lemmatize(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df['processed_tokens'] = trump_df['tokens'].apply(lda_processing)\n",
    "biden_df['processed_tokens'] = biden_df['tokens'].apply(lda_processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df['tokens'].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df['processed_tokens'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_processed_tokens = trump_df['processed_tokens']\n",
    "biden_processed_tokens = biden_df['processed_tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create bags of words on the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_dictionary = gensim.corpora.Dictionary(trump_processed_tokens)\n",
    "biden_dictionary = gensim.corpora.Dictionary(biden_processed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of words in Trump dictionary:\", len(trump_dictionary))\n",
    "print(\"Number of words in Biden dictionary:\", len(biden_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out tokens that appear in less than 10 tweets or more than half the tweets\n",
    "trump_dictionary.filter_extremes(no_below=10, no_above=0.5)\n",
    "biden_dictionary.filter_extremes(no_below=10, no_above=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of words in Trump dictionary after filtering extremes:\", len(trump_dictionary))\n",
    "print(\"Number of words in Biden dictionary after filtering extremes:\", len(biden_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_bow_corpus = [trump_dictionary.doc2bow(tweet) for tweet in trump_processed_tokens]\n",
    "biden_bow_corpus = [biden_dictionary.doc2bow(tweet) for tweet in biden_processed_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve bag of words with TF-IDF\n",
    "We can perform topic modelling directly with our bag of words, but we can further improve it first by incorporating [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_tfidf = models.TfidfModel(trump_bow_corpus)\n",
    "biden_tfidf = models.TfidfModel(biden_bow_corpus)\n",
    "\n",
    "trump_tfidf_corpus = trump_tfidf[trump_bow_corpus]\n",
    "biden_tfidf_corpus = biden_tfidf[biden_bow_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the LDA models with different number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORKERS = 3\n",
    "NUM_PASSES = 15\n",
    "trump_lda_3 = gensim.models.LdaMulticore(trump_tfidf_corpus, num_topics=3, id2word=trump_dictionary, passes=NUM_PASSES, workers=NUM_WORKERS)\n",
    "trump_lda_3.save('trump_lda/trump_lda_3.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_lda_5 = gensim.models.LdaMulticore(trump_tfidf_corpus, num_topics=5, id2word=trump_dictionary, passes=NUM_PASSES, workers=NUM_WORKERS)\n",
    "trump_lda_5.save('trump_lda/trump_lda_5.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_lda_7 = gensim.models.LdaMulticore(trump_tfidf_corpus, num_topics=7, id2word=trump_dictionary, passes=NUM_PASSES, workers=NUM_WORKERS)\n",
    "trump_lda_7.save('trump_lda/trump_lda_7.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_lda_10 = gensim.models.LdaMulticore(trump_tfidf_corpus, num_topics=10, id2word=trump_dictionary, passes=NUM_PASSES, workers=NUM_WORKERS)\n",
    "trump_lda_10.save('trump_lda/trump_lda_10.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_lda_3 = gensim.models.LdaMulticore(biden_tfidf_corpus, num_topics=3, id2word=biden_dictionary, passes=NUM_PASSES, workers=NUM_WORKERS)\n",
    "biden_lda_3.save('biden_lda/biden_lda_3.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_lda_5 = gensim.models.LdaMulticore(biden_tfidf_corpus, num_topics=5, id2word=biden_dictionary, passes=NUM_PASSES, workers=NUM_WORKERS)\n",
    "biden_lda_5.save('biden_lda/biden_lda_5.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_lda_7 = gensim.models.LdaMulticore(biden_tfidf_corpus, num_topics=7, id2word=biden_dictionary, passes=NUM_PASSES, workers=NUM_WORKERS)\n",
    "biden_lda_7.save('biden_lda/biden_lda_7.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_lda_10 = gensim.models.LdaMulticore(biden_tfidf_corpus, num_topics=10, id2word=biden_dictionary, passes=NUM_PASSES, workers=NUM_WORKERS)\n",
    "biden_lda_10.save('biden_lda/biden_lda_10.gensim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at words in each topic with their relative weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, topic in trump_lda_5.print_topics(num_words=7):\n",
    "    print(\"Topic %d:\" %idx, topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, topic in biden_lda_5.print_topics(num_words=7):\n",
    "    print(\"Topic %d:\" %idx, topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test models on a new unseen tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_trump_tweet = 'Big China Virus breakouts all over the World, including nations which were thought to have done a great job. The Fake News doesnâ€™t report this. USA will be stronger than ever before, and soon!'\n",
    "trump_bow_vector = trump_dictionary.doc2bow(lda_processing(basic_processing(unseen_trump_tweet)))\n",
    "\n",
    "for index, score in sorted(trump_lda_5[trump_bow_vector], key=lambda t: t[1], reverse=True):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, trump_lda_5.print_topic(index, topn=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_biden_tweet = 'Our planet canâ€™t take four more years of Donald Trump. We have to get him out of the White House so we can start treating the climate crisis like the urgent threat it is.'\n",
    "biden_bow_vector = biden_dictionary.doc2bow(lda_processing(basic_processing(unseen_biden_tweet)))\n",
    "\n",
    "for index, score in sorted(biden_lda_5[biden_bow_vector], key=lambda t: t[1], reverse=True):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, biden_lda_5.print_topic(index, topn=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "trump_lda5_display = pyLDAvis.gensim.prepare(topic_model=trump_lda_5, corpus=trump_tfidf_corpus, dictionary=trump_dictionary)\n",
    "trump_lda5_display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_lda5_display = pyLDAvis.gensim.prepare(topic_model=biden_lda_5, corpus=biden_tfidf_corpus, dictionary=biden_dictionary)\n",
    "biden_lda5_display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_lda7_display = pyLDAvis.gensim.prepare(topic_model=trump_lda_7, corpus=trump_tfidf_corpus, dictionary=trump_dictionary)\n",
    "trump_lda7_display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_lda7_display = pyLDAvis.gensim.prepare(topic_model=biden_lda_7, corpus=biden_tfidf_corpus, dictionary=biden_dictionary)\n",
    "biden_lda7_display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_lda10_display = pyLDAvis.gensim.prepare(topic_model=trump_lda_10, corpus=trump_tfidf_corpus, dictionary=trump_dictionary)\n",
    "trump_lda10_display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_lda10_display = pyLDAvis.gensim.prepare(topic_model=biden_lda_10, corpus=biden_tfidf_corpus, dictionary=biden_dictionary)\n",
    "biden_lda10_display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we start to get to 10 topics and above, there begins to be an increasing amount of overlap between the topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the literature, it seems that the biterm topic model (BTM) outperforms the traditional LDA algorithm for shorter text documents such as tweets [[source](https://www.cs.toronto.edu/~jstolee/projects/topic.pdf), [source](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.402.4032&rep=rep1&type=pdf)].\n",
    "\n",
    "Future work can include comparing the results of these two models and seeing if we observe the suggested improvements. Can also improve evaluation to use more numerical methods such as topic coherence rather than ad-hoc human interpretation of the topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Classification<a class=\"anchor\" id=\"classification\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classification_results(predictions, y_test, model_name):\n",
    "    print( model_name, \"Accuracy Score:\", accuracy_score(predictions, y_test)*100)\n",
    "    print(model_name, \"Classification Report: \\n\", classification_report(y_test,predictions))\n",
    "    conf_mat = confusion_matrix(y_test, predictions)\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "            xticklabels=['Biden', 'Trump'], yticklabels=['Biden','Trump'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Candidate')\n",
    "    plt.ylabel('True Candidate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign numeric labels to the classes, biden:0, trump:1\n",
    "biden_df['label'] = 0\n",
    "trump_df['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge their two dataframes together into one training dataframe. \n",
    "train_df = pd.concat([trump_df, biden_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tokens which are not stemmed and lemmatized. Using stemmed and lemmatized tokens led to decreased prediction accuracy.\n",
    "# Train on the tf_idf vector of our tokens\n",
    "\n",
    "train_df['training_text'] = train_df['tokens'].apply(TreebankWordDetokenizer().detokenize) \n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(train_df['training_text'])\n",
    "y = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a handful of classifiers that should be good for text classification\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(random_state=0),\n",
    "    MultinomialNB(),\n",
    "    svm.SVC(kernel='linear'),\n",
    "    SGDClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    MLPClassifier(hidden_layer_sizes=(10,), random_state=0),\n",
    "    RandomForestClassifier(n_estimators=150, random_state=0)\n",
    "]\n",
    "\n",
    "# Evaluate with 10-fold cross validation\n",
    "CV = 10\n",
    "classifiers_df = pd.DataFrame(index=range(CV * len(classifiers)))\n",
    "rows = []\n",
    "\n",
    "for clf in classifiers:\n",
    "    print('Training', clf)\n",
    "    clf_name = clf.__class__.__name__\n",
    "    accuracies = cross_val_score(clf, X, y, scoring='accuracy', cv=CV, n_jobs=-1)\n",
    "    for idx, accuracy in enumerate(accuracies):\n",
    "        rows.append((clf_name, idx, accuracy))\n",
    "    \n",
    "classifiers_df = pd.DataFrame(rows, columns=['classifier_name', 'fold', 'accuracy'])\n",
    "classifiers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_df.groupby('classifier_name').mean().drop(columns=['fold']).sort_values(['accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have multiple classifiers that score very highly. Let's use the top three together in a voting classifier to see if we can improve the accuracy even more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,train_df['label'], test_size=0.2)\n",
    "\n",
    "clf1 = MLPClassifier(hidden_layer_sizes=(10,), random_state=0)\n",
    "clf2 = MultinomialNB()\n",
    "clf3 = svm.SVC(kernel='linear')\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('mlp', clf1), ('mnb', clf2), ('svm', clf3)], n_jobs=-1)\n",
    "\n",
    "clf1 = clf1.fit(X_train, y_train)\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "clf3 = clf3.fit(X_train, y_train)\n",
    "eclf = eclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = eclf.predict(X_test)\n",
    "print_classification_results(y_pred, y_test, \"Voting Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Able to slighly improve accuracy from ~93% to ~95% by using the top 3 individual classifiers together in a voting ensemble. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "plt.plot(fpr,tpr,linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
